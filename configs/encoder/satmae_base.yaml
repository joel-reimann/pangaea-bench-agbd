# CONFIGURATION FILE ADDED AS PART OF SATMAE (BASE) INTEGRATION; SOURCE: https://arxiv.org/abs/2207.08051, https://sustainlab-group.github.io/SatMAE/
# Model parameters obtained from: URL  https://github.com/sustainlab-group/SatMAE?tab=readme-ov-file#model-weights-1, then clicked on https://zenodo.org/records/7338613 => choose file "pretrain-vit-base-e199.pth"

#CHOSEN CONFIGURATION BASED ON WEBPAGES MODEL "mae_vit_base_patch16_dec512d8b", with some changes

_target_: pangaea.encoders.satmae_base_encoder.SatMAE_Base
encoder_weights: ./pretrained_models/satmae_pretrain-vit-base-e199.pth
download_url: https://zenodo.org/records/7338613/files/pretrain-vit-base-e199.pth?download=1

model_name: SatMAE_Base

input_size: 96    ## from https://github.com/sustainlab-group/SatMAE?tab=readme-ov-file#pretraining-1, according to pre-training settings described on paper
in_chans: 3       # Number of groups -> see Code in SatMAE GitHub => channel_groups=((0, 1, 2, 6), (3, 4, 5, 7), (8, 9))
embed_dim: 768    # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
patch_size: 8     # from https://github.com/sustainlab-group/SatMAE?tab=readme-ov-file#pretraining-1, not DEFAULT value for the model on SatMAE GitHub (was 16 but didnt work)
num_heads: 12     # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
depth: 12         # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
mlp_ratio: 4.     # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
mask_ratio: 0     # pre-trained with 0.75, but for fine-tuning keep at 0

# Further variables from Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub: (excluded all decoder related variables)
channel_embed: 256
qkv_bias: True    # from Code on SatMAE GitHub, default value

input_bands:      # channel_groups=((0, 1, 2, 6), (3, 4, 5, 7), (8, 9)); Source: From the paper https://arxiv.org/pdf/2207.08051
  optical:
    - B2          # 0
    - B3          # 1
    - B4          # 2
    - B5          # 3
    - B6          # 4
    - B7          # 5
    - B8          # 6
    - B8A         # 7
    - B11         # 8
    - B12         # 9

output_layers:    # Default according to PANGAEA GitHub file "CONTRIBUTING.md". 3,5,7,11
  - 3
  - 5
  - 7
  - 11


output_dim: 2304  # its embed_dim * in_chans * (1-mask_ratio) ; dimension of the embedding output by the encoder, accepted by the decoder (src: base.py in present code structure)
pyramid_output: False # output not in pyramid form